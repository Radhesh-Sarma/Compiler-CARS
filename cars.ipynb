{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "cars.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Radhesh-Sarma/Compiler-CARS/blob/main/cars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYMCkh7ONdyD"
      },
      "source": [
        "#CARS\r\n",
        "\r\n",
        "###Our language is named 'CARS'\r\n",
        "###Parser designed in Python 3.x\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsLOYNu7a_1Q"
      },
      "source": [
        "# Group Details\r\n",
        "\r\n",
        "* Radhesh Sarma: 2017B4A70886H\r\n",
        "* Chatrik Singh Mangat: 2017B5A70822H\r\n",
        "* Ashi Sinha: 2017B5A71149H\r\n",
        "* Simran Sahni: 2017B5A70856H\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xONiIfKEbDFo"
      },
      "source": [
        "## Parser Capabilities\r\n",
        "\r\n",
        "Current parser capabilites:\r\n",
        "1) Tokenizing & identifying the tokens\r\n",
        "\r\n",
        "2) Lines starting with '#' are skipped, only single line comments supported right now\r\n",
        "\r\n",
        "3) Read the C files in the same folder line by line & parse it, calling the Class token objects & static methods\r\n",
        "\r\n",
        "4) A big dictionary of all possible token kinds is maintained & checked from"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5qsfEEbJRB"
      },
      "source": [
        "## BNF for our Mini Language\r\n",
        "\r\n",
        "  \r\n",
        "* `<program> -> <statement><delimiter>|<delimiter>`\r\n",
        "*  `<statement> -> <keyword><var><operator><var><delimiter> | <statement> | `\r\n",
        "*  `<conditional><statement> | <loop><statement>`\r\n",
        "* `<keyword> -> true | false | return | void | main`\r\n",
        "* `<datatype> -> int | float | boolean | string | while`\r\n",
        "* `<loop> -> while<statement>{}| for<statement> {} | until<statement> {}`\r\n",
        "* `<conditional> -> if <statement> {} | else <statement> {}`\r\n",
        "* `<var> -> <datatype><id>|<id>`\r\n",
        "* `<operator> -> +| - | % | / | * | == | > | < | >= | <= | != |&&| || | | ! \t\t | ? | : | = | \" | $`\r\n",
        "* `<delimiter> ->  { | } | ( | ) | [ | ] | , | ;`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38xe9GbibRqR"
      },
      "source": [
        "## Basic syntactical rules\r\n",
        "\r\n",
        "1) strings only in double quotes\r\n",
        "\r\n",
        "2) all standard data-types recognized in keywords\r\n",
        "\r\n",
        "3) Most of the arithmetic & boolean operators supported\r\n",
        "\r\n",
        "4) Identifier names cannot start with numbers & cant include any substring that is a keyword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih3d7GhbZr2b"
      },
      "source": [
        "##Defining the token categories of our language's grammar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP6YANDQZh-x"
      },
      "source": [
        "keywords = ['int','float','boolean','string','while','until','if','else','true','false','return','void','main','for']\r\n",
        "operators = ['+','-','*','/','%','==','>','<','>=','<=','!=','&&','||','!','?',':','=','\"','$']\r\n",
        "delimiters = ['{','}','(',')','[',']',',',';']\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "504tuJkwaFeB"
      },
      "source": [
        "##Token kinds validation helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PFHcMaRZ6bx"
      },
      "source": [
        "def is_valid_identifier(string):\r\n",
        "    ok = True\r\n",
        "    if(string == ''):\r\n",
        "        return False\r\n",
        "    if(string[0] >='0' and string[0]<='9'):\r\n",
        "        return False\r\n",
        "    for x in keywords:\r\n",
        "        if(string.startswith(x) or string.endswith(x)):\r\n",
        "            return False\r\n",
        "    for x in delimiters:\r\n",
        "        if(string.startswith(x) or string.endswith(x)):\r\n",
        "            return False\r\n",
        "    for x in operators:\r\n",
        "        if(string.startswith(x) or string.endswith(x)):\r\n",
        "            return False\r\n",
        "    return ok\r\n",
        "\r\n",
        "\r\n",
        "def is_alphanumeric(ch):\r\n",
        "    ok = False\r\n",
        "    if(ch>='a' and ch<='z'):\r\n",
        "        ok = True\r\n",
        "    elif(ch>='A' and ch<='Z'):\r\n",
        "        ok = True\r\n",
        "    elif(ch>='0' and ch<='9'):\r\n",
        "        ok = True\r\n",
        "    elif(ch=='.'):\r\n",
        "        ok = True\r\n",
        "    return ok\r\n",
        "\r\n",
        "def is_delimiter(ch):\r\n",
        "    ok = False\r\n",
        "    for x in delimiters:\r\n",
        "        if(x==ch):\r\n",
        "            ok = True\r\n",
        "    return ok\r\n",
        "\r\n",
        "def is_operator(ch):\r\n",
        "    return Token.is_valid(ch)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-X1O5OxNo0D"
      },
      "source": [
        "## Class Token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6HRGMTGMXbW"
      },
      "source": [
        "class Token:\n",
        "    __token_list = {}\n",
        "    __counter = 1\n",
        "    __token_types = ['keyword','operator','delimiter','identifier','integer literal','floating point literal']\n",
        "    def __init__(self,kind,string):\n",
        "        if kind not in Token.__token_types:\n",
        "          raise ValueError\n",
        "        self.kind = kind\n",
        "        self.string = string\n",
        "        self.number = self.__counter\n",
        "        Token.__counter += 1\n",
        "        Token.__token_list[self.string] = {'kind':self.kind , 'string':self.string, 'number':self.number}\n",
        "\n",
        "    @staticmethod\n",
        "    def is_valid(string):\n",
        "        return string in Token.__token_list.keys() and Token.__token_list[string]['kind'] != 'identifier'\n",
        "\n",
        "    @staticmethod\n",
        "    def get_token_details(word):\n",
        "        if(Token.is_valid(word)):\n",
        "            return Token.__token_list[word]\n",
        "        if(word.isnumeric()):\n",
        "            ob = Token('integer literal',word)\n",
        "        elif(True):\n",
        "            try:\n",
        "                float(word)\n",
        "                ob = Token('floating point literal',word)\n",
        "            except ValueError:\n",
        "                if(is_valid_identifier(word)):\n",
        "                    ob = Token('identifier',word)\n",
        "        return Token.__token_list[word]\n",
        "\n",
        "    @staticmethod\n",
        "    def print_all_tokens():\n",
        "        for token in Token.__token_list:\n",
        "            print(token)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csKCW8HRNtuJ"
      },
      "source": [
        "##Making Token objects "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_fbKdEHaaf1"
      },
      "source": [
        "for keyword in keywords:\r\n",
        "    Token('keyword',keyword)\r\n",
        "\r\n",
        "for operator in operators:\r\n",
        "    Token('operator',operator)\r\n",
        "\r\n",
        "for delimiter in delimiters:\r\n",
        "    Token('delimiter',delimiter)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA00tYvoN3vr"
      },
      "source": [
        "##List of Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8o52LrxMXbj",
        "outputId": "c21a1f61-cd5b-40e3-be27-ed1f7c1e4b32"
      },
      "source": [
        "Token.print_all_tokens()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int\n",
            "float\n",
            "boolean\n",
            "string\n",
            "while\n",
            "until\n",
            "if\n",
            "else\n",
            "true\n",
            "false\n",
            "return\n",
            "void\n",
            "main\n",
            "for\n",
            "+\n",
            "-\n",
            "*\n",
            "/\n",
            "%\n",
            "==\n",
            ">\n",
            "<\n",
            ">=\n",
            "<=\n",
            "!=\n",
            "&&\n",
            "||\n",
            "!\n",
            "?\n",
            ":\n",
            "=\n",
            "\"\n",
            "$\n",
            "{\n",
            "}\n",
            "(\n",
            ")\n",
            "[\n",
            "]\n",
            ",\n",
            ";\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GYTMaJ7auMq"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjsvfbnMbhLK"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRxEUCWvbhm5"
      },
      "source": [
        "##Reading the file\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbyM6TtmcyzB"
      },
      "source": [
        "file = open(\"prog2.txt\", \"r\")\r\n",
        "\r\n",
        "input = file.read()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAr0DsNTMXbl",
        "outputId": "93329655-b88e-445c-a5a1-ffd510c047cf"
      },
      "source": [
        "print(input)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float ffff = 123.1.1;\n",
            "itn x;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCmJsfzcN-fY"
      },
      "source": [
        "#Parsing Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLdiyO66MXbl",
        "outputId": "71e49afb-571f-42ea-aa5c-7782cf99a4eb"
      },
      "source": [
        "ch = ''  #This string read the input file word by word\n",
        "line_number = 0\n",
        "\n",
        "for line in input.splitlines():\n",
        "    line_number += 1\n",
        "\n",
        "    for i in line:\n",
        "        if(i.startswith('#')):      #it is a comment so ignore that line\n",
        "            break\n",
        "        if(is_alphanumeric(i)):\n",
        "            ch+=i\n",
        "        elif(is_delimiter(i) or is_operator(i)):\n",
        "            if(ch!=''):\n",
        "                try:\n",
        "                    print(\"Token: \" + str(ch) + \" \", \" Token Details : \" + str(Token.get_token_details(ch)), \" Line number \" + str(line_number))\n",
        "                except:\n",
        "                    print(\"Error!!!!! INVALID TOKEN \" + str(ch) + \" Line number \" + str(line_number))\n",
        "\n",
        "            print(\"Token: \" + str(i) + \" \", \" Token Details : \" + str(Token.get_token_details(i)), \" Line number \" + str(line_number))\n",
        "            ch=''\n",
        "        elif(ord(i) == 32 or i=='\\n'):\n",
        "            if(ch!=''):\n",
        "                try:\n",
        "                    print(\"Token: \" + str(ch) + \" \", \" Token Details : \" + str(Token.get_token_details(ch)), \" Line number \" + str(line_number))\n",
        "                except:\n",
        "                    print(\"Error!!!!! INVALID TOKEN \" + str(ch) + \" Line number \" + str(line_number))\n",
        "                finally:\n",
        "                    ch = ''\n",
        "        else:\n",
        "            print(\"Error!!!!! INVALID TOKEN \" + str(i) + \" Line number \" + str(line_number))  "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token: float   Token Details : {'kind': 'keyword', 'string': 'float', 'number': 2}  Line number 1\n",
            "Token: ffff   Token Details : {'kind': 'identifier', 'string': 'ffff', 'number': 42}  Line number 1\n",
            "Token: =   Token Details : {'kind': 'operator', 'string': '=', 'number': 31}  Line number 1\n",
            "Error!!!!! INVALID TOKEN 123.1.1 Line number 1\n",
            "Token: ;   Token Details : {'kind': 'delimiter', 'string': ';', 'number': 41}  Line number 1\n",
            "Token: itn   Token Details : {'kind': 'identifier', 'string': 'itn', 'number': 43}  Line number 2\n",
            "Token: x   Token Details : {'kind': 'identifier', 'string': 'x', 'number': 44}  Line number 2\n",
            "Token: ;   Token Details : {'kind': 'delimiter', 'string': ';', 'number': 41}  Line number 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skGeasRAMXbm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}